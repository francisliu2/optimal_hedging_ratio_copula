{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copulae1 import *\n",
    "from KDEs import *\n",
    "from toolbox import *\n",
    "import json\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and params\n",
    "spot_name = 'rs'\n",
    "future_name = 'rf'\n",
    "\n",
    "spotCoin = 'eth'\n",
    "\n",
    "data_name = '%sUSD_BTCUSD_25SEP20'%spotCoin.upper()\n",
    "OHR_path = 'best_h/%s/'%data_name\n",
    "data_path = '/Volumes/external_SSD/copulaData/Deribit_ready2/%s/'%data_name\n",
    "\n",
    "# NIG\n",
    "NIG_LL = pd.read_csv('data_%sLL_hourly_NIG_btc.csv'%spotCoin)\n",
    "NIG_h_path = 'data_%s_hourly/'%spotCoin\n",
    "NIG_h = [l for l in os.listdir('data_%s_hourly'%spotCoin) if l.endswith('.csv')]\n",
    "\n",
    "\n",
    "k_arr = [10] # Absolute risk aversion for exponential risk measure\n",
    "q_arr_ES = [.01, .05] # Quantile level for expected shortfall\n",
    "q_arr_VaR = [.01, .05] # Quantile level for Value at Risk\n",
    "\n",
    "# Load files\n",
    "ls = os.listdir(OHR_path)\n",
    "ls = [l for l in ls if l.endswith('.pickle')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hedging_effectiveness(rm, rs, rf, h):\n",
    "\tif rm.startswith('Variance'):\n",
    "\t\trh = rs - h * rf\n",
    "\t\treturn 1 - Variance(rh) / Variance(rs)\n",
    "\n",
    "\telif rm.startswith('ERM'):\n",
    "\t\tk = float(rm[rm.find('=') + 1:])\n",
    "\t\trh = rs - h * rf\n",
    "\t\treturn 1 - ERM_estimate_trapezoidal(k, rh) / ERM_estimate_trapezoidal(k, rs)\n",
    "\n",
    "\telif rm.startswith('ES'):\n",
    "\t\tq = float(rm[rm.find('=') + 1:])\n",
    "\t\trh = rs - h * rf\n",
    "\t\treturn 1 - ES(q, rh) / ES(q, rs)\n",
    "\n",
    "\telif rm.startswith('VaR'):\n",
    "\t\tq = float(rm[rm.find('=') + 1:])\n",
    "\t\trh = rs - h * rf\n",
    "\t\treturn 1 - VaR(q, rh) / VaR(q, rs)\n",
    "\n",
    "def wrapper_HE(rm, file, h, insample=True):\n",
    "\tif insample:\n",
    "\t\tdata = pd.read_csv(data_path + 'train/' + file)\n",
    "\telse:\n",
    "\t\tdata = pd.read_csv(data_path + 'test/' + file)\n",
    "\trs = data.loc[:, spot_name]\n",
    "\trf = data.loc[:, future_name]\n",
    "\treturn hedging_effectiveness(rm, rs, rf, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanNIG(file, NIG_h_path):\n",
    "\n",
    "    fileName = file.replace('_h','')\n",
    "\n",
    "    NIG_h_dict = {'Variance':0, 'VaR q=0.01':0, 'VaR q=0.05':0, 'ES q=0.01':0, \n",
    "                  'ES q=0.05':0, 'ERM k=10':0}\n",
    "    text_list = []\n",
    "    with open(NIG_h_path+file, \"r\") as my_input_file:\n",
    "        for line in my_input_file:\n",
    "            line = line.replace('\\n','')\n",
    "            line = line.split(\",\", 2)\n",
    "            text_list.append(\" \".join(line))\n",
    "    # text_list = text_list[1:7]\n",
    "    NIG_h_dict['Variance'] = float(text_list[1])\n",
    "    NIG_h_dict['VaR q=0.01'] = float(text_list[2])\n",
    "    NIG_h_dict['VaR q=0.05'] = float(text_list[3])\n",
    "    NIG_h_dict['ES q=0.01'] = float(text_list[4])\n",
    "    NIG_h_dict['ES q=0.05'] = float(text_list[5])\n",
    "    NIG_h_dict['ERM k=10'] = float(text_list[6])\n",
    "\n",
    "    _df = pd.DataFrame(NIG_h_dict, index=[fileName])\n",
    "    _df = _df.T.reset_index()\n",
    "    _df.loc[:, 'copula'] = 'NIG'\n",
    "    _df.loc[:, 'file'] = fileName\n",
    "    _df.columns = ['risk_measure', 'h', 'copula', 'file']\n",
    "    return _df\n",
    "\n",
    "NIG_h_df = []\n",
    "\n",
    "for file in NIG_h:\n",
    "    NIG_h_df.append(cleanNIG(file,  NIG_h_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186it [00:31,  5.87it/s]\n"
     ]
    }
   ],
   "source": [
    "HEs = []\n",
    "\n",
    "for i, OHR_file in tqdm(enumerate(ls)):\n",
    "    OHR = pd.read_pickle(OHR_path+OHR_file)\n",
    "    OHR = pd.melt(OHR.reset_index(), id_vars='index')\n",
    "    file = OHR_file[:OHR_file.find('.csv')+4]\n",
    "    OHR.columns = ['copula', 'risk_measure', 'h']\n",
    "    OHR.loc[:,'file'] = file\n",
    "    NIG_file = file.replace('.csv', '_h.csv')\n",
    "    OHR = pd.concat([OHR, cleanNIG(NIG_file, NIG_h_path)], axis=0)\n",
    "    \n",
    "    OHR.loc[:, 'HE'] = OHR.apply(lambda x: wrapper_HE(rm=x.risk_measure,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tfile=x.file,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\th=x.h,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tinsample=True), axis=1)\n",
    " \n",
    "    HEs.append(OHR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEs = pd.concat(HEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIG_likelihood = pd.read_csv('data_%sLL_hourly_NIG_btc.csv'%spotCoin)\n",
    "likelihood = pd.read_pickle('%sUSD_BTCUSD_25SEP20_likelihood.pickle'%spotCoin.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186it [00:02, 75.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, OHR_file in tqdm(enumerate(ls)):\n",
    "#     print(i, len(ls))\n",
    "    file = OHR_file[:OHR_file.find('.csv')+4]\n",
    "    _id = HEs.file == file\n",
    "    NIG_LL = float(NIG_likelihood.loc[int(file.replace('.csv', '')), :].LL)\n",
    "\n",
    "    likelihood[file].append(('NIG', NIG_LL))\n",
    "\n",
    "    for l in likelihood[file]:\n",
    "        _id2 = _id & (HEs.copula == l[0])\n",
    "        HEs.loc[_id2, 'likelihood'] = l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = {'Gaussian':1,\n",
    "     't_Copula':2, \n",
    "     't_Copula_Capped':2, \n",
    "     'Clayton':1, \n",
    "     'Frank':1, \n",
    "     'Gumbel':1,  \n",
    "     'Plackett':1,  \n",
    "     'Gauss Mix Indep':2, \n",
    "     'rotGumbel':1, \n",
    "     'NIG':3}\n",
    "\n",
    "HEs.loc[:,'AIC'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove t_copula_capped\n",
    "HEs = HEs.loc[HEs.copula != 't_Copula_Capped', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "copula_names = list(k.keys())\n",
    "for c in copula_names:\n",
    "    _id = HEs.copula == c\n",
    "    HEs.loc[_id, 'AIC'] = -2*HEs.loc[_id, 'likelihood'] + 2*k[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_table = HEs.loc[:,['file', 'copula', 'AIC']]\n",
    "AIC_table.drop_duplicates(inplace=True)\n",
    "AIC_table.sort_values('AIC', inplace=True)\n",
    "\n",
    "AIC_selection = []\n",
    "\n",
    "for file in np.unique(AIC_table.file):\n",
    "    _id = AIC_table.file==file\n",
    "    c = AIC_table.loc[_id,'copula'].iloc[0]\n",
    "    AIC_selection.append([file, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEs.loc[:,'AIC_selected'] = 0\n",
    "HEs.sort_values(['copula'], inplace=True)\n",
    "HEs.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in AIC_selection:\n",
    "    file = row[0]\n",
    "    c = row[1]\n",
    "\n",
    "    _id = (HEs.file == file) & (HEs.copula == c)\n",
    "    HEs.loc[_id, 'AIC_selected'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>copula</th>\n",
       "      <th>risk_measure</th>\n",
       "      <th>h</th>\n",
       "      <th>file</th>\n",
       "      <th>HE</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>AIC</th>\n",
       "      <th>AIC_selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5778</th>\n",
       "      <td>NIG</td>\n",
       "      <td>Variance</td>\n",
       "      <td>1.055844</td>\n",
       "      <td>1.csv</td>\n",
       "      <td>0.669015</td>\n",
       "      <td>192.176119</td>\n",
       "      <td>-378.352238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>NIG</td>\n",
       "      <td>VaR q=0.01</td>\n",
       "      <td>1.209680</td>\n",
       "      <td>1.csv</td>\n",
       "      <td>0.362401</td>\n",
       "      <td>192.176119</td>\n",
       "      <td>-378.352238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>NIG</td>\n",
       "      <td>VaR q=0.05</td>\n",
       "      <td>1.032977</td>\n",
       "      <td>1.csv</td>\n",
       "      <td>0.481286</td>\n",
       "      <td>192.176119</td>\n",
       "      <td>-378.352238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>NIG</td>\n",
       "      <td>ES q=0.01</td>\n",
       "      <td>1.191398</td>\n",
       "      <td>1.csv</td>\n",
       "      <td>0.495057</td>\n",
       "      <td>192.176119</td>\n",
       "      <td>-378.352238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>NIG</td>\n",
       "      <td>ES q=0.05</td>\n",
       "      <td>1.100571</td>\n",
       "      <td>1.csv</td>\n",
       "      <td>0.461423</td>\n",
       "      <td>192.176119</td>\n",
       "      <td>-378.352238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>NIG</td>\n",
       "      <td>ERM k=10</td>\n",
       "      <td>1.013516</td>\n",
       "      <td>1.csv</td>\n",
       "      <td>0.453264</td>\n",
       "      <td>192.176119</td>\n",
       "      <td>-378.352238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Clayton</td>\n",
       "      <td>VaR q=0.05</td>\n",
       "      <td>1.139746</td>\n",
       "      <td>1.csv</td>\n",
       "      <td>0.439387</td>\n",
       "      <td>48.195320</td>\n",
       "      <td>-94.390639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7798</th>\n",
       "      <td>Plackett</td>\n",
       "      <td>VaR q=0.05</td>\n",
       "      <td>1.083887</td>\n",
       "      <td>1.csv</td>\n",
       "      <td>0.500678</td>\n",
       "      <td>174.812919</td>\n",
       "      <td>-347.625838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>Gumbel</td>\n",
       "      <td>VaR q=0.01</td>\n",
       "      <td>1.506250</td>\n",
       "      <td>1.csv</td>\n",
       "      <td>0.384783</td>\n",
       "      <td>163.760094</td>\n",
       "      <td>-325.520187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7619</th>\n",
       "      <td>Plackett</td>\n",
       "      <td>Variance</td>\n",
       "      <td>1.031934</td>\n",
       "      <td>1.csv</td>\n",
       "      <td>0.667394</td>\n",
       "      <td>174.812919</td>\n",
       "      <td>-347.625838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        copula risk_measure         h   file        HE  likelihood  \\\n",
       "5778       NIG     Variance  1.055844  1.csv  0.669015  192.176119   \n",
       "5829       NIG   VaR q=0.01  1.209680  1.csv  0.362401  192.176119   \n",
       "5833       NIG   VaR q=0.05  1.032977  1.csv  0.481286  192.176119   \n",
       "5841       NIG    ES q=0.01  1.191398  1.csv  0.495057  192.176119   \n",
       "5842       NIG    ES q=0.05  1.100571  1.csv  0.461423  192.176119   \n",
       "5843       NIG     ERM k=10  1.013516  1.csv  0.453264  192.176119   \n",
       "193    Clayton   VaR q=0.05  1.139746  1.csv  0.439387   48.195320   \n",
       "7798  Plackett   VaR q=0.05  1.083887  1.csv  0.500678  174.812919   \n",
       "5315    Gumbel   VaR q=0.01  1.506250  1.csv  0.384783  163.760094   \n",
       "7619  Plackett     Variance  1.031934  1.csv  0.667394  174.812919   \n",
       "\n",
       "             AIC  AIC_selected  \n",
       "5778 -378.352238             1  \n",
       "5829 -378.352238             1  \n",
       "5833 -378.352238             1  \n",
       "5841 -378.352238             1  \n",
       "5842 -378.352238             1  \n",
       "5843 -378.352238             1  \n",
       "193   -94.390639             0  \n",
       "7798 -347.625838             0  \n",
       "5315 -325.520187             0  \n",
       "7619 -347.625838             0  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = HEs.file=='1.csv'\n",
    "HEs.loc[_id, ].sort_values(\"AIC_selected\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>copula</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gauss Mix Indep</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gumbel</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIG</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotGumbel</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_Copula</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 eth\n",
       "copula              \n",
       "Gauss Mix Indep   45\n",
       "Gumbel             1\n",
       "NIG               46\n",
       "rotGumbel         29\n",
       "t_Copula          65"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIC_selection = pd.DataFrame(AIC_selection)\n",
    "AIC_selection.columns = [spotCoin, 'copula']\n",
    "AIC_summary = pd.pivot_table(AIC_selection, index='copula', values='copula', aggfunc='count')\n",
    "AIC_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEs.to_csv('%s_HEs.csv'%spotCoin)\n",
    "AIC_summary.to_csv('%s_AIC_summary.csv'%spotCoin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
