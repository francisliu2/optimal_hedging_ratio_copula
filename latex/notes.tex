%%
%% $Id: article.tex,v 1.1 2008/09/20 10:19:28 natalie Exp $
%% $Source: /Users/natalie/cvs/tex/templates/article.tex,v $
%% $Date: 2008/09/20 10:19:28 $
%% $Revision: 1.1 $
%%

%\documentclass[a4paper,11pt,BCOR1cm,DIV11,headinclude]{scrbook}
% bei 12pt ist DIV 12 default, bei 11pt ist es DIV 10
% Textbereiche 
% DIV 10: 147*207.9mm, DIV 11: 152.73*216mm, DIV 12:157.50*222.75
% DIV 13: 161.54*228.46mm, DIV 14: 165*233.36mm

\def\deftitle{Notes on hedging cryptos with spectral risk measures}
% \def\defauthor{N.\ Packham}
% \def\defauthor{nat}
\def\defauthor{}

%% option: largefont
\documentclass[square]{article} %
%% options: vscreen, garamond, wnotes, savespace
\usepackage[vscreen]{nat}
\usepackage[longnamesfirst]{natbib}
\usepackage{booktabs}

\bibpunct{(}{)}{;}{a}{,}{,}
\usepackage{amsfonts,amssymb,amsthm} %
\usepackage{mathrsfs}
\usepackage[tbtags]{amsmath} %
\usepackage{bm}
\usepackage{tabularx,ragged2e}
\usepackage[table,xcdraw]{xcolor}
\usepackage{subfig}

\newcolumntype{C}{>{\Centering\arraybackslash}X}
\newcolumntype{s}{>{\hsize=.2\hsize \Centering\arraybackslash}X}
% \usepackage{fullpage}
\usepackage{footnote}
\makesavenoteenv{tabular}

\usepackage{graphicx,color}
\graphicspath{{./pics/}}
\definecolor{BrickRed}{rgb}{.625,.25,.25}
\providecommand{\red}[1]{\textcolor{BrickRed}{#1}}
\definecolor{markergreen}{rgb}{0.6, 1.0, 0}
\definecolor{darkgreen}{rgb}{0, .5, 0}
\definecolor{darkred}{rgb}{.7,0,0}
\definecolor{markergreen}{rgb}{0.6, 1.0, 0}
\definecolor{darkgreen}{rgb}{0, .5, 0}
\definecolor{darkorange}{rgb}{1,0.3,0}
\definecolor{darkred}{RGB}{.7,0,0}
\definecolor{darkblue}{RGB}{0,29,245}
\definecolor{orange}{RGB}{239, 133, 54}
\definecolor{lightblue}{RGB}{59, 188, 175}

\providecommand{\marker}[1]{\fcolorbox{markergreen}{markergreen}{{#1}}}
\providecommand{\natp}[1]{\textcolor{darkred}{#1}}
\providecommand{\mj}[1]{\textcolor{darkred}{#1}}
\providecommand{\francis}[1]{\textcolor{darkgreen}{#1}}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}%[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary} %%
\newtheorem{lemma}[theorem]{Lemma} %%
\theoremstyle{definition} %%
\newtheorem{definition}{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{remarks}{Remarks}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}{Assumption}
\setlength{\parindent}{0pt}

\usepackage[makestderr]{pythontex}
\usepackage{amsmath}
\begin{pycode}
import numpy as np
from scipy import stats
import statsmodels.api as sm
import pandas as pd
import matplotlib.pyplot as plt
np.random.seed(87654)
\end{pycode}


\input{definitions}
\sloppy
\begin{document}
\setlength{\boxlength}{0.95\textwidth} %
\title{\large{\bf\deftitle}} %
\author{{\normalsize\bf\defauthor}}%
\thispagestyle{empty}
\addtocounter{page}{1}
\maketitle
\begin{abstract}
  We investigate different methods of hedging cryptocurrencies with
  Bitcoin futures. A useful generalisation of variance-based hedging
  uses spectral risk measures and copulas. 
\end{abstract}
% \keywords{keywords here} %%
% \jel{jel here} %%
\vspace{.5cm}
\def\contentsname{Contents}
\tableofcontents
%%
\vspace{.5cm}
% \clearpage

\section{TODO}
\label{sec:todo}

\begin{itemize}
\item Discussion on calibration using method of moments. Make clear
  that creating a hedge with one instrument is linear, so only
  co-movement can be hedged. With BTC we see quite a few
  counter-movement events, so this might be idiosyncratic risk, but it
  might also point to another risk factor that could be hedged
  separately
\item Basis risk: the risk that prices of financial instruments in a
  hedging strategy are imperfectly correlated, reducing the
  effectiveness of the hedging strategy (see {\tt
    Minimum-capital-requirements-for-market-risk-BIS-2019.pdf}). 
\end{itemize}

\section{Optimal hedge ratio}
\label{sec:optimal-hedge-ratio}

Following \citep{Barbi2014}, we consider the problem of optimal
hedge ratios by extending the commmonly known minimum variance hedge
ratio to more general risk measures and dependence
structures.\medskip

Hedge portfolio: $R_t^h = R_t^S - h R_t^F$, involving returns of spot
and future contract and where $h$ is the hedge ratio

Optimal hedge ratio: $h^\ast = \argmin_h \rho_\phi(s,h)$, for given
confidence level $1-s$ (if applicable, e.g.\ in the case of VaR, ES),
where $\rho_\phi$ is a spectral risk measure with weighting function
$\phi$ (see below).

The distribution function of $r^h$ can be expressed in terms of the
copula and the marginal distributions as Proposition \ref{prop:dfrh}
result shows (this is a corrected version of Corollary 2.1 of
\citep{Barbi2014}). For practical applications, it is numerically
faster and more stable to use additional information about the
specific copula and marginal distributions. We therefore derive
semi-analytic formulas for a number of special cases, such as the
Gaussian-, Student $t$-, normal inverse Gaussian (NIG) and Archimedean
copulas in Section \ref{sec:dependence}.

\begin{proposition}
  \label{prop:dfrh}
  Let $r^S$ and $r^F$ be two real-valued random variables on the same
  probability space $(\Omega, \mathcal A, \p)$ with corresponding
  absolutely continuous copula $C_{r^S, r^F}s$ and
  continuous marginals $F_{r^S}$ and $F_{r^F}$. Then, the distribution
  of of $r^h$ is given by
  \begin{equation}
    \label{eq:3}
    F_{r^h}(x) = 1- \int^1_0 D_1 C_{r^S, r^F}
    \left( u, F_{r^F} \left( \frac{F^{-1}_{r^S}(u)-x}{h} \right)
    \right)\, \dd u.
  \end{equation}
\end{proposition}\medskip
Here $D_1 C(u,v)=\displaystyle \frac{\partial}{\partial u} C(u,v)$,
which is easily shown to fulfil, see e.g.\ Equation (5.15) of
\citep{McNeil2005}:\footnote{%
  Let $F_X(x)=u$, $F_Y(y)=v$. Then, formally,
  \begin{align*}
    \frac{\partial}{\partial F_X(x)} C(F_X(x), F_Y(y)) %
    &= \frac{\partial}{\partial F_X(x)} \p(U\leq F_X(x),
      V\leq F_Y(y)) %
      = \p(U\in \dd F_X(x), V\leq F_Y(y))\\ %
    &= \p(V\leq F_Y(y)| U = F_X(x))\cdot \p(U \in \dd
      F_X(x)) %
      = \p(Y\leq y|X=x)\cdot \p(U\in \dd u)\\ %
    &= \p(Y\leq y|X=x).
  \end{align*}}
\begin{equation}
  \label{eq:1}
  D_1 C_{X,Y}(F_X(x), F_Y(y)) = \p(Y\leq y|X=x).
\end{equation}
\begin{proof}
  Using the identity (\ref{eq:1}) gives
  \begin{align*}
    F_{r^h}(x) &= \p(r^S - h r^F\leq x) %
                 = \E\left[\p\left(r^F\geq \frac{r^S-x}{h}\Big|
                 r^S\right)\right]\\[10pt]
               &= 1-\E\left[\p\left(r^F\leq \frac{r^S-x}{h}\Big|
                 r^S\right)\right]% \\[10pt]
               = 1- \int_0^1 D_1 C_{r^S, r^F}\left(u,
                 F_{r^F}\left(\frac{F^{(-1)}_{r^S}(u) -
                 x}{h}\right)\right)\, \dd u.
  \end{align*}
\end{proof}\medskip

In addition to \cite{Barbi2014} we propose a more handy expression for the density of $r^h$

\begin{prop} With the same setting of the above proposition, the density of $r^h$ can be written as
  \begin{align}
  f_{r^h}(y) &= \left|\frac{1}{h}\right|\int_0^1 c_{r^S, r^F} \left[u,
  F_{r^F}\left\{\frac{F^{-1}_{r^S}(u)-y}{h}\right\}
  \right]
   \cdot
  f_{r^F}
  \left\{\frac{F^{-1}_{r^S}(u)-y}{h}\right\} du \label{eq:density1}
  \end{align}, or
    \begin{align}
      f_{r^h}(y)
      = \int_0^1 c_{r^S, r^F} \left[u,
      F_{r^S}\left\{y + h F^{-1}_{r^F}(u)\right\}
      \right]
       \cdot
      f_{r^S}
      \left\{
      y+ hF^{-1}_{r^F}(u).
      \right\} du\label{eq:density2}
  \end{align}
  \end{prop}
The two expression are equivalent.
One can use any of them to get the density of $r^h$.
Notice that the density of $r^h$ in the above proposition is readily accessible as long as we have
the copula density and the marginal densities.
A generic expression can be found in the appendix (TODO).
\begin{figure}[h]
\includegraphics[width=\textwidth]{_pics/density illustration1.png}
\includegraphics[width=\textwidth]{_pics/density illustration2.png}
  \caption{Upper Panel: Density of $r^h= r^S - hr^F$ of different copulas with
  $r^S, r^F \sim N(0,1)$,
  0.75 Spearman's rho between $r^S$ and $r^F$, and $h=0.5$;
  Lower Panel: Scatter plot of samples from copulas.
  This illustration shows how dependence structure modelled by copulas affects the density of the linear combination
  of margins.
  Notice that the $r^h$ modelled by the asymmetric copulas namely the Clayton and Gumbel copulas are skewed to right
  and left respectively.}
\label{fig:density illustration}
\end{figure}
  % \begin{align*}
  %   C(u,v) &=\int_0^1 \frac{\partial}{\partial u} C(u,v)\, \dd u %
  %            = \int_0^1 \frac{\partial}{\partial u} \p(U\leq u, V\leq v)\, \dd
  %            u \\ %
  %          &= \int_0^1 \p(U\in \dd u, V\leq v)\, \dd u %
  %            = \int_0^1 \p(V\leq v|U=u) \underbrace{\p(U\in \dd
  %            u)}_{=1}\, \dd u\\
  %          &= \int_0^1 \p(V\leq v|U=u) \, \dd u %
  %            % = \int_\R \p(F_Y(Y)\leq F_Y(y) |F_X(X) = F_X(x))\, \dd
  %            % F_X(x) \\
  %          = \int_\R \p(F_Y(Y)\leq F_Y(y) |F_X(X) = F_X(x))\, f_X(x) \dd
  %            x %
  %            = \int_\R \p(Y\leq y|X=x)\, f_X(x) \dd x. 
  % \end{align*}
  % Consequently $\displaystyle \frac{\partial}{\partial u} C(u,v) =
  % \frac{\partial}{\partial F(x)} C(F(x), F(y)) = \p(Y\leq y|X=x)$
  % $\pas$.

\section{Spectral risk measures}
\label{sec:spectr-risk-meas}

Spectral risk measure \citep{Acerbi2002,Cotter2006}:
\begin{equation*}
\rho_\phi = -\int_0^1 \phi(p)\, q_p\, \dd p,
\end{equation*}
where $q_p$ is the $p$-quantile of the return distribution and
$\phi(s)$, $s\in [0,1]$, is the so-called {\em risk aversion
  function\/}, a weighting function such that\footnote{Note that the
  treatment in \citep{Acerbi2002} is measure-based and therefore
  slightly different.} 
\begin{enumerate}[(i)]
\item $\phi(p)\geq 0$,
\item $\int_0^1\phi(p)\, \dd p=1$,
\item $\phi'(p)\leq 0$. 
\end{enumerate}
Examples: VaR, ES\\
Replacing the last property with $\phi'(p)>0$ rules out risk-neutral
behaviour. \\
Spectral risk measures are coherent \citep{Acerbi2002}. 

\subsection{Representation of spectral risk measures}
\label{sec:repr-spectr-risk}

To prevent numerical instabilities involving the quantile function,
re-write spectral risk measures as follows:
\begin{itemize}
\item Integration by substitution: $\displaystyle \int_a^b
  g(\varphi(x)) \,\varphi'(x)\, \dd x = \int_{\varphi(a)}^{\varphi(b)}
  g(u)\, \dd u$.
\item Spectral risk measures: $\displaystyle -\int_0^1 \phi(p) \,
  F^{(-1)}(p)\, \dd p$
\item Set $\varphi(x)=F(x)$, $g(p) = \phi(p)\, F^{(-1)}(p)$.
\item Then:
  \begin{equation*}
    -\int_0^1 \phi(p)\, F^{(-1)}(p)\, \dd p = -\int_{-\infty}^\infty
    \phi(F(x))\, x\, f(x)\, \dd x.
  \end{equation*}
\end{itemize}


\subsection{Exponential spectral risk measures}
\label{sec:expon-risk-meas}

\begin{itemize}
\item Choose exponential utiliy function:
  $\displaystyle U(x) = -\e^{-k x}$, where $k>0$ is the Arrow-Pratt
  coefficient of absolute risk aversion
  (ARA).
\item Coefficient of absolute risk aversion: $\displaystyle R_A(x) =
  -\frac{U''(x)}{U'(x)} = k$
\item Coefficient of relative risk aversion: $\displaystyle R_R(x) = -
  \frac{x U''(x)}{U'(x)} = xk$
\item Weighting function $\phi(p) = \lambda \e^{-k(1-p)}$, where
  $\lambda$ is an unknown positive constant.
\item Set $\displaystyle\lambda = \frac{k}{1-\e^{-k}}$ to satisfy
  normalisation.
\item Exponential spectral risk measure:
  \begin{equation*}
    \rho_{\phi} = \int_0^1 \phi(p)\, F^{(-1)}(p)\, \dd p =
    \frac{k}{1-\e^{-k}} \int_0^1 \e^{-k(1-p)}\, F^{(-1)}(p)\, \dd p. 
  \end{equation*}
(If calculation of quantiles is a problem use change of variables
above.)
\item What exactly is the link between risk measure and utility?
    I think there is no direct link: the exponential risk measure is
   {\em inspired\/} by ARA utility.
\end{itemize}

\section{Hedge effectiveness}
\label{sec:hedge-effectiveness}

(Ederington, 1979): hedge effectiveness similar to $R^2$
(Barbi R.): similar, but with actual risk measures (e.g.\ VaR)

This uses the optimisation criterion to check out-of-sample
performance of each method. It'll be interesting to compare across
methods in which respect methods meet their target.

Also use P\&L to compare across methods, this might give insights to
what extent methods achieve their objective and how this compares
across methods (e.g.\ hedging general risk vs.\ hedging tail risk). 

%\input{methodology.tex}
\input{D1Operator.tex}

\section{Special copulas}
\label{sec:dependence}
\input{dependence.tex}

\clearpage
\section{Estimation}
\input{estimation.tex}

\clearpage

\section{Backtesting}
\label{sec:backtesting}

Especially for VaR and ES, at the 99\% level, but also at the 95\%
level, out-of-sample testing the hedge effectiveness by means of a
30-day window may lead to unstable results. To evaluate these risk
measures we therefore employ backtesting techniques from Basel
regulation \natp{(references here)}.

\section{Backtesting value-at-risk}
\label{sec:backtesting-value-at}

The standard procedure for backtesting VaR, the so-called ``traffic
light approach'', dates back to the beginnings of VaR and Basel
regulation \cite{Basel1996b}. The method is described in e.g.\ Section
2.3 of \cite{McNeil2005}.

At time $t$, let $\text{VaR}_\alpha^t$ denote the true one-period 
value-at-risk (VaR) at the confidence level $\alpha$. The realised
P\&L of the position, $\Delta V_t=V_{t+1}-V_t$, is assumed to follow a
continuous distribution. % Because at time $t$, $\p(\Delta V_t\leq
% \text{VaR}_\alpha^t)=1-\alpha$, the probability of a violation of VaR
% is $1-\alpha$.
A violation (also called exception or outlier) of VaR is expressed by
the Bernoulli variable 
$\1_{t+1}:=\1_{\{\Delta V_t>\text{VaR}_\alpha^t\}}$.
If the sequence $(\1_{t+1})_{t\in \Z}$ is adapted 
to the filtration $(\mathcal F_t)_{t\in \Z}$ and $\E(\1_{t+1}|\mathcal
F_t)=1-p$, for all $t$, then $(\1_t)_{t\in \Z}$ is a process of 
identically distributed Bernoulli variables, see 
Lemma 4.29 \cite{McNeil2005}.


In order to backtest a VaR model, 
one-period estimates are 
compared against realised P\&L of the
position, giving a sequence $\hat\1_{t+1}:=\hat\1_{\{\Delta V_t >
  \widehat{\text{VaR}}_\alpha^t\}}$, $t+1=1, \ldots, n$. If indeed the
model measures VaR at the given level $\alpha$, then the number of
violations $X$ follows a binomial distribution, i.e., $X\sim
B(n,1-p)$. The ``traffic light approach'' in the Basel accord
specifies the acceptable number of violations such that falsely
rejecting the null hypothesis of a vaild model at most 5\%. In
our setting, because $n\cdot p$ is sufficiently large, we approximate
the number of violations by a normal distribution, i.e.\
$X\stackrel{a}{\sim} \displaystyle \Ncdf\left(n\, p, 
  n\, p(1-p)\right)$ and hence reject the null hypothesis if
\begin{equation*}
  \frac{\hat X-n\, p}{\sqrt{n\, p(1-p)}} > \Ncdf_{1-\delta},
\end{equation*}
where $\delta$ denotes the level of statistical significance. 

\input{robustness.tex}

\input{data.tex}

\input{hedgingeffectiveness.tex}


\input{summarystatistics.tex}
\input{table.tex}



\clearpage
\bibliographystyle{abbrvnamed} %
\bibliography{finance} %
\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
